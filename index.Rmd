---
title: "HR Analytics in R"
author: "Chester Ismay, Albert Y. Kim and Hendrik Feddersen"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: pdf_document
bibliography:
- bib/books.bib
- bib/packages.bib
- bib/articles.bib
colorlinks: yes
cover-image: images/hranalytics.jpg
apple-touch-icon: images/logos/favicons/apple-touch-icon.png
description: An open-source self-training book to assist you in your journey to sustainable
  HR Analytics
documentclass: krantz
favicon: images/logos/favicons/favicon.ico
fontsize: 12pt, krantz2
github-repo: Hendrik147/HR_Analytics_in_R_book
graphics: yes
link-citations: yes
lof: yes
lot: yes
monofont: Source Code Pro
monofontoptions: Scale=0.7
biblio-style: apalike
site: bookdown::bookdown_site
subtitle: Common tasks achieved with the power of R
always_allow_html: yes
url: https\://hranalyticslive.netlify.com/
---

<!-- For use only in PDF, is skipped in HTML -->
\mainmatter

```{r set-options, include=FALSE}

# Current version information: Date here should match the date in the YAML above.
# Remove .9000 tag and set date to release date when releasing
version <- "0.6.0"
date <- format(Sys.time(), '%B %d, %Y')

# Set output options
if(knitr:::is_html_output())
  options(width = 80)
if(knitr:::is_latex_output())
  options(width = 75)
options(digits = 7, bookdown.clean_book = TRUE, knitr.kable.NA = 'NA')
knitr::opts_chunk$set(
  tidy = FALSE, 
  out.width = '\\textwidth', 
  fig.align = "center", 
  comment = NA
) 

# CRAN packages needed
needed_CRAN_pkgs <- c(
  # Data packages:
  "nycflights13", "ggplot2movies", "fivethirtyeight", "gapminder", "ISLR",
  
  # Explicitly used packages:
  "tidyverse", "rmarkdown", "knitr", "janitor", #"skimr",
  "infer", "moderndive","googleway","rebus",
  
  # Internally used packages:
  "webshot", "mvtnorm", "remotes", "devtools", "dygraphs", "gridExtra",
  "kableExtra", "googledrive","scales", "viridis", "ggrepel", "patchwork",
  
  # Other packages used in HR Analytics section:
  "bigstatsr",
  "bookdown","choroplethr","choroplethrMaps","data.table","datasets",
  "dlnm","dplyr","faraway","forcats","GGally","ggthemes","GISTools","gsubfn",
  "httr","ibmsunburst","influenceR","leaflet","lubridate","magrittr","microbenchmark",
  "pander","pdftools","plotly","poppler-cpp",
  "profvis","pryr","purrr","rappdirs","raster","rattle","RColorBrewer","readr","rebus",
  "rmarkdown","rvest","scales","seriation","sp","stats","stringr","testthat","tidyr",
  "tidymodels","tigris","titanic","viridis") 


new_pkgs <- needed_CRAN_pkgs[!(needed_CRAN_pkgs %in% installed.packages())]
if(length(new_pkgs)) {
  install.packages(new_pkgs, repos = "http://cran.rstudio.com")
}
if(!"skimr" %in% installed.packages()){
  # Install non-2.0 version of skimr so that histograms can be removed easily
  remotes::install_version("skimr", version = "1.0.6")
}
# GitHub packages needed
#remotes::install_github("tidymodels/infer", ref = "develop")
#remotes::install_github("moderndive/moderndive")

# GitHub packages needed
needed_pkgs <- unique(c(needed_CRAN_pkgs, 
                        "skimr",  "moderndive", "infer", "bookdown"))

# Check that phantomjs is installed to create screenshots of apps
if(is.null(webshot:::find_phantom()))
  webshot::install_phantomjs()

# Automatically create a bib database for R packages
knitr::write_bib(
  c(.packages(), "bookdown", "knitr", "rmarkdown", "nycflights13",
    "ggplot2", "webshot", "dygraphs", "dplyr",
    "ggplot2movies", "fivethirtyeight", "tibble", "readr", "tidyr",
    "janitor", "infer", "skimr", "kableExtra",
    "bookdown","choroplethr","choroplethrMaps","data.table","datasets",
    "dlnm","dplyr","faraway","forcats","GGally","ggthemes","GISTools",
    "httr","ibmsunburst","leaflet","lubridate","magrittr","microbenchmark",
    "pander","profvis","plyr","purrr","rappdirs","raster","rattle","RColorBrewer",
    "readr","rmarkdown","scales","sp","stats","stringr","testthat","tidyr",
    "tigris","titanic","viridis"),
  "bib/packages.bib"
)

# Add all simulation results here
if(!dir.exists("rds"))
  dir.create("rds")

# Create empty docs folder
if(!dir.exists("docs")) dir.create("docs")

# Make sure all images copy to docs folder
if(!dir.exists("docs/images")) dir.create("docs/images")
system("cp -r images/* docs/images/")

# These steps are only needed for generating the moderndive.com page
# with relevant links. Not needed for PDF generation.
if(knitr::is_html_output()){
  # Add all knitr::purl()'ed chapter R scripts here
  system("rm -rf docs/scripts/")
  if(!dir.exists("docs/scripts"))
    dir.create("docs/scripts")
    system('"C:/Program Files (x86)/R-3.6.0/bin/x64/R.exe" CMD BATCH --vanilla --slave
            "C:/Users/hfedd/AppData/Local/gitkraken/pp-6.5.1/HR_Analytics_in_R_book_local_clone/HR_Analytics_in_R_book/purl.R"')
    system('rm "C:/Users/hfedd/AppData/Local/gitkraken/pp-6.5.1/HR_Analytics_in_R_book_local_clone/HR_Analytics_in_R_book/purl.Rout"')
  
  # Copy all needed csv and txt files to docs/
  # Should switch to use purrr here at some point
  if(!dir.exists("docs/data"))
    dir.create("docs/data")
  file.copy("data/dem_score.csv", "docs/data/dem_score.csv", overwrite = TRUE)
  file.copy("data/dem_score.xlsx", "docs/data/dem_score.xlsx", overwrite = TRUE)
  file.copy("data/le_mess.csv", "docs/data/le_mess.csv", overwrite = TRUE)
  file.copy("data/ideology.csv", "docs/data/ideology.csv", overwrite = TRUE)
  # For Appendix B
  file.copy("data/ageAtMar.csv", "docs/data/ageAtMar.csv", overwrite = TRUE)
  file.copy("data/offshore.csv", "docs/data/offshore.csv", overwrite = TRUE)
  file.copy("data/cleSac.txt", "docs/data/cleSac.txt", overwrite = TRUE)
  file.copy("data/zinc_tidy.csv", "docs/data/zinc_tidy.csv", overwrite = TRUE)
  
  # To be updated to include the actual link to labs (likely in blogdown format?)
  # when Albert has those ready
  file.copy("labs.html", "docs/labs.html", overwrite = TRUE)
  file.copy("regression-plane.html", "docs/regression-plane.html", overwrite = TRUE)
  # Copy previous_versions/ to docs/previous_versions/
  # Should switch to use purrr here at some point
  if(!dir.exists("docs/previous_versions"))
    dir.create("docs/previous_versions/")
  system("cp -r previous_versions/* docs/previous_versions/")
  
# For some reason logo needs to be done separately.
# Loaded in _includes/logo.html
file.copy("images/logos/hranalytics.jpg", "docs/hranalytics.jpg", overwrite = TRUE)

# Copy pdf file if needed
if(file.exists("hendrikfeddersen.pdf"))
  file.copy("hendrikfeddersen.pdf", "docs/hendrikfeddersen.pdf", overwrite = TRUE)
}

# Set ggplot2 theme to be light if outputing to PDF.
library(ggplot2)
if(knitr::is_latex_output()){
  theme_set(theme_light())
} else {
  theme_set(theme_grey())
}

# For generating the R script files at the end of relevant chapters
generate_r_file_link <- function(file){
  if(knitr::is_latex_output()){
    cat(glue::glue("An R script file of all R code used in this chapter is available at <https://https://hranalyticslive.netlify.com//scripts/{file}>."))
  } else {
    cat(glue::glue("An R script file of all R code used in this chapter is available [here](scripts/{file})."))
  }
}

# To get kable tables to print nicely in .tex file
if(knitr::is_latex_output())
  options(kableExtra.auto_format = FALSE, knitr.table.format = "latex")
```

```{r images, include=FALSE}
include_image <- function(path,                           
                          html_opts = "width=45%", 
                          latex_opts = html_opts,
                          alt_text = ""){
  if(knitr:::is_html_output()){
    glue::glue("![{alt_text}]({path}){{ {html_opts} }}")
  } else if(knitr:::is_latex_output()){
    glue::glue("![{alt_text}]({path}){{ {latex_opts} }}")    
  }
}

image_link <- function(path,
                       link,
                       html_opts = "height: 200px;",
                       latex_opts = "width=0.2\\textwidth",
                       alt_text = "",
                       centering = TRUE){
  if(knitr:::is_html_output()){
    if(centering){
      glue::glue('
      <center><a target="_blank" class="page-link" href="{link}"><img src="{path}" style="{html_opts}"/></a></center>')
    } else {
      glue::glue('
      <a target="_blank" class="page-link" href="{link}"><img src="{path}" style="{html_opts}"/></a>')
    }
  }
  else if(knitr:::is_latex_output()){
    if(centering){
      glue::glue('\\begin{{center}}
        \\href{{{link}}}{{\\includegraphics[{latex_opts}]{{{path}}}}}
        \\end{{center}}')
    } else
      glue::glue('\\href{{{link}}}{{\\includegraphics[{latex_opts}]{{{path}}}}}')
  }
}
```



```{block, type='learncheck', include=!knitr::is_latex_output(), purl=FALSE}
**Please note that you are currently looking at the latest version of “HR Analytics in R”. However, since work is still in progress it is subject to frequent change.**
```
```{r, echo=FALSE, include=!knitr::is_latex_output(), purl=FALSE}
dev_version <- TRUE
```
</br>
```{r echo=FALSE, purl=FALSE, results="asis"}
if(knitr::is_html_output()){
  include_image(path = "images/logos/book_cover.png", 
                html_opts="width=350px")
}
```
</br>


# Introduction {#intro}


***

```{block, type='learncheck', purl=FALSE}
**Please note that you are currently looking at the latest version of "HR Analytics in R". However, since work is still in progress it is subject to change.**
```

The intention of this book is to encourage more 'data driven' decisions in HR. HR Analytics is not anymore a nice-to-have addon but rather the way HR practitioners should conduct HR decision making in the future. Where applicable, human judgement is 'added' onto a rigorous analysis of the data done in the first place.

To achieve this ideal world, I need to equip you with some fundamental knowledge of R and RStudio, which are open-source tools for data scientists. I am well aware that on one side you want to do something for your career in HR, however you are most likely completely new to coding.


\vspace{0.1in}



<center>

`r include_image("images/logos/Rlogo.png", html_opts = "height=100px", latex_opts = "height=10%")`        \hfill &emsp; &emsp; &emsp; `r include_image("images/logos/RStudio-Logo-Blue-Gradient.png", html_opts = "height=100px", latex_opts = "height=10%")`

</center>



**Help! I'm new to R and RStudio and I need to learn about them! However, I'm completely new to coding! What do I do?** 



\vspace{0.1in}



<!--

<img src="images/logos/Rlogo.svg" style="height: 150px;"/>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

<img src="images/logos/RStudio-Logo-Blue-Gradient.png" style="height: 150px;"/>

-->

If you're asking yourself this question, then you have come to the right place! There is no better moment to ride the wave of disruptions taking place now in HR.

* *Are you looking to learn about HR Analytics utilising the power of R"? Then start with our [Introduction for Students](#sec:intro-for-students).*
* *Are you looking to contribute to "HR Analytics in R"? Then click [here](#sec:connect-contribute) for information on how.*
* *Are you curious about the publishing of this book? Then click [here](#sec:about-book) for more information on the open-source technology, in particular R Markdown and the bookdown package.*

This is version `r version` of "HR Analytics in R" published on `r date`. While a PDF version of this book can be found [here](hendrikfeddersen.pdf){target="_blank"}, this is very much a work in progress with many things that still need to be fixed. I appreciate your patience. 



***



## Introduction for students {#sec:intro-for-students}

This book assumes no prerequisites: no algebra, no calculus, and no prior programming/coding experience. This is intended to be a gentle introduction to the practice of analyzing data and answering questions using data the way data scientists, statisticians and other researchers would. 

### Working with the material {#workingwithmaterials .unnumbered}

You can work your way through the materials by clicking on the arrows to the left and right at the bottom of each page. Alternatively, there is a collapsible contents bar on the left hand side.

If you need to find something specific, you can use the search icon. Typing in a word or phrase will filter the contents bar to relevant sections.

The book by default renders black sans serif on a white background. You can use the A to amend the appearance of the book to make it easier to process, whether that’s a larger font, a serif font, or a different colour scheme.

The edit button takes you straight to github, where you can propose editorial changes.

### Conventions {#conventions .unnumbered}

Throughout this book various conventions will be used.

In terms of basic formatting:

* This is standard text.
* `This is code or a symbol`
* *This is a Keyboard Key!*
* **This is the first time I mention something important**

This is a book about coding, so expect code blocks. Code blocks will typically look like this:

```{r}
"this is a code block"
```

Directly underneath it, normally starting with two hash symbols (##) is the result of the code executing.

```{r}
## [1] 'this is a code block'`
```

There will also be callouts throughout the book. Some are for information, some expect you to do things.

Anything written here should be read carefully before proceeding.

This is a tip relating to what I’ve just said.

This is kind of like a tip but is for when you’re getting into trouble and need help.

This is something I recommend you do as you’re reading.

In Figure \@ref(fig:moderndive-figure) I present a flowchart of what you'll cover in this book. You'll first get started with data in Chapter \@ref(getting-started), where you'll learn about the difference between R and RStudio, start coding in R, understand what R packages are, and explore your first dataset: all domestic departure flights from a New York City airport in 2013. Then

1. **Data science**: You'll assemble your data science toolbox using `tidyverse` packages. In particular:
    + Ch.\@ref(viz): Visualizing data via the `ggplot2` package.
    + Ch.\@ref(tidy): Understanding the concept of "tidy" data as a standardized data input format for all packages in the `tidyverse`
    + Ch.\@ref(wrangling): Wrangling data via the `dplyr` package.
1. **Data modeling**: Using these data science tools and helper functions from the `moderndive` package, you'll start performing data modeling. In particular:
    + Ch.\@ref(regression): Constructing basic regression models.
    + Ch.\@ref(multiple-regression): Constructing multiple regression models.
1. **Statistical inference**: Once again using your newly acquired data science tools, I'll unpack statistical inference using the `infer` package. In particular:
    + Ch.\@ref(sampling): Understanding the role that sampling variability plays in statistical inference using both tactile and virtual simulations of sampling from a "bowl" with an unknown proportion of red balls.
    + Ch.\@ref(confidence-intervals): Building confidence intervals.
    + Ch.\@ref(hypothesis-testing): Conducting hypothesis tests.
1. **Data modeling revisited**: Armed with your new understanding of statistical inference, you'll revisit and review the models you constructed in Ch.\@ref(regression) & Ch.\@ref(multiple-regression). In particular:
    + Ch.\@ref(inference-for-regression): Interpreting both the statistical and practice significance of the results of the models.
    + Ch.\@ref(thinking-with-data): I'll end the introductory chapters with a discussion on what it means to "think with data" and present an example case study data analysis of house prices in Seattle.
1. **HR Analytics - data driven decision making**: The intention is to provide real tangible examples of the application of data science to HR, to illustrate the data science process in the HR context, and to show that the scope mentioned previously in this article, isn't just theoretical - it's real. The last and most important module shall illustrate current best practices of a structured process of thinking and analysis. 


```{r moderndive-figure, echo=FALSE, fig.align='center', fig.cap="ModernDive Flowchart", fig.width=8}
knitr::include_graphics("images/flowcharts/flowchart/flowchart.002.png")
```





### What you will learn from this book {#subsec:learning-goals}

I hope that by the end of this book, you'll have learned

1. How to use R to explore data.  
1. How to answer statistical questions using tools like confidence intervals and hypothesis tests. 
1. How to effectively create "data stories" using these tools. 

What do I mean by data stories? I mean any analysis involving data that engages the reader in answering questions with careful visuals and thoughtful discussion, such as [How strong is the relationship between per capita income and crime in Chicago neighborhoods?](http://rpubs.com/ry_lisa_elana/chicago) and [How many f**ks does Quentin Tarantino give (as measured by the amount of swearing in his films)?](https://ismayc.github.io/soc301_s2017/group_projects/group4.html).  Further discussions on data stories can be found in this [Think With Google article](https://www.thinkwithgoogle.com/marketing-resources/data-measurement/tell-meaningful-stories-with-data/).  

For other examples of data stories constructed by students like yourselves, look at the final projects for two courses that have previously used ModernDive:

* Middlebury College [MATH 116 Introduction to Statistical and Data Sciences](https://rudeboybert.github.io/MATH116/PS/final_project/final_project_outline.html#past_examples) using student collected data.
* Pacific University [SOC 301 Social Statistics](https://ismayc.github.io/soc301_s2017/group-projects/index.html) using data from the [fivethirtyeight R package](https://cran.r-project.org/web/packages/fivethirtyeight/vignettes/fivethirtyeight.html).

This book will help you develop your "data science toolbox", including tools such as data visualization, data formatting, data wrangling, and data modeling using regression. With these tools, you'll be able to perform the entirety of the "data/science pipeline" while building data communication skills (see Subsection \@ref(subsec:pipeline) for more details). 

In particular, this book will lean heavily on data visualization.  In today's world, we are bombarded with graphics that attempt to convey ideas.  I will explore what makes a good graphic and what the standard ways are to convey relationships with data.  You'll also see the use of visualization to introduce concepts like mean, median, standard deviation, distributions, etc.  In general, I'll use visualization as a way of building almost all of the ideas in this book.

To impart the statistical lessons in this book, I have intentionally minimized the number of mathematical formulas used and instead have focused on developing a conceptual understanding via data visualization, statistical computing, and simulations.  I hope this is a more intuitive experience than the way statistics has traditionally been taught in the past and how it is commonly perceived.

Finally, you'll learn the importance of literate programming.  By this I mean you'll learn how to write code that is useful not just for a computer to execute but also for readers to understand exactly what your analysis is doing and how you did it.  This is part of a greater effort to encourage reproducible research (see Subsection \@ref(subsec:reproducible) for more details). Hal Abelson coined the phrase that I will follow throughout this book:

> "Programs must be written for people to read, and only incidentally for machines to execute."

I understand that there may be challenging moments as you learn to program.  Both of us continue to struggle and find ourselves often using web searches to find answers and reach out to colleagues for help.  In the long run though, we all can solve problems faster and more elegantly via programming.  I wrote this book as our way to help you get started and you should know that there is a huge community of R users that are always happy to help everyone along as well.  This community exists in particular on the internet on various forums and websites such as [stackoverflow.com](https://stackoverflow.com/).

### Data/science pipeline {#subsec:pipeline}

You may think of statistics as just being a bunch of numbers.  I commonly hear the phrase "statistician" when listening to broadcasts of sporting events.  Statistics (in particular, data analysis), in addition to describing numbers like with baseball batting averages, plays a vital role in all of the sciences.  You'll commonly hear the phrase "statistically significant" thrown around in the media.  You'll see articles that say "Science now shows that chocolate is good for you."  Underpinning these claims is data analysis.  By the end of this book, you'll be able to better understand whether these claims should be trusted or whether we should be wary.  Inside data analysis are many sub-fields that I will discuss throughout this book (though not necessarily in this order):

- data collection
- data wrangling
- data visualization
- data modeling
- inference
- correlation and regression
- interpretation of results
- data communication/storytelling

These sub-fields are summarized in what Grolemund and Wickham term the ["Data/Science Pipeline"](http://r4ds.had.co.nz/explore-intro.html) in Figure \@ref(fig:pipeline-figure).

```{r pipeline-figure, echo=FALSE, fig.align='center', fig.cap="Data/Science Pipeline"}
knitr::include_graphics("images/tidy1.png")
```

I will begin by digging into the gray **Understand** portion of the cycle with data visualization, then with a discussion on what is meant by tidy data and data wrangling, and then conclude by talking about interpreting and discussing the results of our models via **Communication**.  These steps are vital to any statistical analysis.  But why should you care about statistics?  "Why did they make me take this class?"

There's a reason so many fields require a statistics course. Scientific knowledge grows through an understanding of statistical significance and data analysis. You needn't be intimidated by statistics.  It's not the beast that it used to be and, paired with computation, you'll see how reproducible research in the sciences particularly increases scientific knowledge.

### Reproducible research {#subsec:reproducible}

> "The most important tool is the _mindset_, when starting, that the end product will be reproducible." – Keith Baggerly

Another goal of this book is to help readers understand the importance of reproducible analyses. The hope is to get readers into the habit of making their analyses reproducible from the very beginning.  This means I'll be trying to help you build new habits.  This will take practice and be difficult at times. You'll see just why it is so important for you to keep track of your code and well-document it to help yourself later and any potential collaborators as well.  

Copying and pasting results from one program into a word processor is not the way that efficient and effective scientific research is conducted.  It's much more important for time to be spent on data collection and data analysis and not on copying and pasting plots back and forth across a variety of programs.

In a traditional analyses if an error was made with the original data, we'd need to step through the entire process again:  recreate the plots and copy and paste all of the new plots and our statistical analysis into your document.  This is error prone and a frustrating use of time.  I'll see how to use R Markdown to get away from this tedious activity so that we can spend more time doing science.

> "We are talking about _computational_ reproducibility." - Yihui Xie

Reproducibility means a lot of things in terms of different scientific fields.  Are experiments conducted in a way that another researcher could follow the steps and get similar results?  In this book, I will focus on what is known as **computational reproducibility**.  This refers to being able to pass all of one's data analysis, data-sets, and conclusions to someone else and have them get exactly the same results on their machine.  This allows for time to be spent interpreting results and considering assumptions instead of the more error prone way of starting from scratch or following a list of steps that may be different from machine to machine.

<!--
Additionally, this book will focus on computational thinking, data thinking, and inferential thinking. I'll see throughout the book how these three modes of thinking can build effective ways to work with, to describe, and to convey statistical knowledge.  
-->

### Final note for students

At this point, if you are interested in instructor perspectives on this book, ways to contribute and collaborate, or the technical details of this book's construction and publishing, then continue with the rest of the chapter below.  Otherwise, let's get started with R and RStudio in Chapter \@ref(getting-started)!



***



## Introduction for instructors {#sec:intro-instructors}

This book is inspired by the following books:

- "Mathematical Statistics with Resampling and R" [@hester2011],
- "OpenIntro: Intro Stat with Randomization and Simulation" [@isrs2014], and 
- "R for Data Science" [@rds2016].


The first book, while designed for upper-level undergraduates and graduate students, provides an excellent resource on how to use resampling to impart statistical concepts like sampling distributions using computation instead of large-sample approximations and other mathematical formulas.  The last two books are free options to learning introductory statistics and data science, providing an alternative to the many traditionally expensive introductory statistics textbooks. 

When looking over the large number of introductory statistics textbooks that currently exist, I found that there wasn't one that incorporated many newly developed R packages directly into the text, in particular the many packages included in the [`tidyverse`](http://tidyverse.org/) collection of packages, such as `ggplot2`, `dplyr`, `tidyr`, and `broom`. Additionally, there wasn't an open-source and easily reproducible textbook available that exposed new learners all of three of the learning goals listed at the outset of Subsection \@ref(subsec:learning-goals).

### Who is this book for?

This book is intended for instructors of traditional introductory statistics classes using RStudio, either the desktop or server version, who would like to inject more data science topics into their syllabus. I assume that students taking the class will have no prior algebra, calculus, nor programming/coding experience.

Here are some principles and beliefs I kept in mind while writing this text. If you agree with them, this might be the book for you.

1. **Blur the lines between lecture and lab**
    + With increased availability and accessibility of laptops and open-source non-proprietary statistical software, the strict dichotomy between lab and lecture can be loosened.
    + It's much harder for students to understand the importance of using software if they only use it once a week or less.  They forget the syntax in much the same way someone learning a foreign language forgets the rules. Frequent reinforcement is key.
1. **Focus on the entire data/science research pipeline**
    + I believe that the entirety of Grolemund and Wickham's [data/science pipeline](http://r4ds.had.co.nz/introduction.html) should be taught.
    + I believe in ["minimizing prerequisites to research"](https://arxiv.org/abs/1507.05346): students should be answering questions with data as soon as possible.
1. **It's all about the data**
    + I leverage R packages for rich, real, and realistic data-sets that at the same time are easy-to-load into R, such as the `nycflights13` and `fivethirtyeight` packages.
    + I believe that [data visualization is a gateway drug for statistics](http://escholarship.org/uc/item/84v3774z) and that the Grammar of Graphics as implemented in the `ggplot2` package is the best way to impart such lessons. However, I often hear: "You can't teach `ggplot2` for data visualization in intro stats!" I, like [David Robinson](http://varianceexplained.org/r/teach_ggplot2_to_beginners/), are much more optimistic.
    + `dplyr` has made data wrangling much more [accessible](http://chance.amstat.org/2015/04/setting-the-stage/) to novices, and hence much more interesting data-sets can be explored. 
1. **Use simulation/resampling to introduce statistical inference, not probability/mathematical formulas**
    + Instead of using formulas, large-sample approximations, and probability tables, statistical concepts using resampling-based inference.
    + This allows for a de-emphasis of traditional probability topics, freeing up room in the syllabus for other topics.
1. **Early exposure to analytics and computing**
    + Computing skills are essential to working with data in the 21st century even for HR managers. Given this fact, I feel that an early exposure to computing can only be of benefit to the whole HR community.
    + I am not teaching a course on coding/programming per se, but rather just enough of the computational and algorithmic thinking necessary for performing a data analysis in HR.
1. **Complete reproducibility and customisability**
    + I am frustrated when people talk about HR Analytics, without giving the source code and the data itself. I give you the source code for all examples as well as the whole book!
    + If you want you can even use my book as a starting point and customise for your own non-profit training. For more about how to make this book your own, see [About this Book](#sec:about-book).



***



## Connect and contribute {#sec:connect-contribute}

If you would like to connect with "HR Analytics in R", check out the following links:

* If you would like to receive periodic updates about HR Analytics, then please sign up for my [mailing list](https://hranalytics.live/signup/). You will receive receive bi-weekly notififications about my new blog posts.
* Please feel free to contact me at [info@hranalytics.live](mailto:info@hranalytics.live) .
* I am on Twitter at [h_feddersen](https://twitter.com/h_feddersen).

If you would like to contribute to "HR Analytics in R", there are many ways! Let's all work together to make this book as great as possible for as many students as possible!

* Please let me know if you find any errors, typos, or areas from improvement on my [GitHub issue page](https://github.com/Hendrik147/HR_Analytics_in_R_book/issues) page. I will fix it as soon as possible.
* If you are familiar with GitHub and would like to contribute even more, please see Section \@ref(sec:about-book) below.

I would like to thank [Moderndive](https://github.com/moderndive/moderndive_book) for their inspirational presentation at a recent R user conference and for their generous example on how to set up a bookdown book and for their introductory pages on how to start using R.



***



## About this book {#sec:about-book}

This book was written using RStudio's [bookdown](https://bookdown.org/) package by Yihui Xie [@R-bookdown]. This package simplifies the publishing of books by having all content written in [R Markdown](http://rmarkdown.rstudio.com/html_document_format.html).

* **Latest published version, still in development** The most up-to-date version, which is still in development is available at [https://hranalyticslive.netlify.com/](https://hranalyticslive.netlify.com/)
* **Source code** The bookdown/R Markdown source code for the latest version of "HR Analytics in R" is available on Hendrik Feddersen's [GitHub repository page](https://github.com/Hendrik147/HR_Analytics_in_R_book)
* **Usage** You can share this material with colleagues or for non-commercial purposes but you can’t resell or incorporate them into stuff you make money from. 
    + As a symbol of gratitude, I would expect at least that you to sign up for my [mailing list](https://hranalytics.live/signup/). 
    + If you think my material is awesome and want to use it for commercial purposes, please contact me at [info@hranalytics.live](mailto:info@hranalytics.live)

* **Licence** This work is licensed under a Creative Commons
    Attribution-NonCommercial 4.0 International License.
    
    ![Creative Commons License](images/by-nc-sa.png)

***



## About the author {#sec:about-authors}

Who am I? I am Hendrik Feddersen, a long-standing HR practitioner passionate about HR Analytics and living in Amsterdam, the Netherlands.

`r include_image(path = "images/Photo HF Snappy.jpg", html_opts = "height=200px", latex_opts = "width=40%")`

<!-- <img src="images/Photo HF Snappy.jpg" alt="Drawing" style="height: 200px;"/>-->


* Email: [info@hranalytics.live](mailto:info@hranalytics.live)
* Webpage: <https://hranalytics.live/>
* Twitter: [h_feddersen](https://twitter.com/h_feddersen)
* GitHub: <https://github.com/Hendrik147>


<!-- For use only in PDF, is skipped in HTML -->
\mainmatter
